# Install Vertical Pod Autoscaler

Sometimes things aren’t clear right away. That’s where you need to be patient and persevere and see where things lead.

– Mary Pierce

## Introduction to Kubernetes Vertical Pod Autoscaler (VPA)

### 1

**Lab Objective**
In this lab, you will install and configure the Vertical Pod Autoscaler (VPA) in your Kubernetes cluster. The lab will walk you through the installation of VPA using predefined manifests, cloning the VPA repository for advanced control, and deploying a sample application to see how VPA interacts with it. Additionally, you'll learn how to troubleshoot issues using VPA logs.

By the end of this lab, you should be able to:

Install VPA and its components (Recommender, Updater, Admission Controller) in a Kubernetes cluster
Understand the role of each VPA component and how they contribute to efficient resource management
Deploy a sample application to see how VPA recommends and adjusts resources for it
Troubleshoot resource-related issues in your application using logs generated by the VPA components, particularly the VPA Updater
This hands-on experience will give you the skills to manage pod resources dynamically in a production-grade Kubernetes environment, ensuring that applications run efficiently with the appropriate resource requests.

### 2

We have prepared the required YAML files for you to deploy the Vertical Pod Autoscaler (VPA). Simply follow the steps below to apply the necessary configurations:

**Step 1** Install VPA Custom Resource Definitions (CRDs)
These CRDs allow Kubernetes to recognize the custom resources that VPA uses to function properly. To install them, run this command:

```bash
kubectl apply -f /root/vpa-crds.yml

customresourcedefinition.apiextensions.k8s.io/verticalpodautoscalercheckpoints.autoscaling.k8s.io created
customresourcedefinition.apiextensions.k8s.io/verticalpodautoscalers.autoscaling.k8s.io created
```


```yaml
# vpa-crds.yml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    api-approved.kubernetes.io: https://github.com/kubernetes/kubernetes/pull/63797
    controller-gen.kubebuilder.io/version: v0.9.2
  creationTimestamp: null
  name: verticalpodautoscalercheckpoints.autoscaling.k8s.io
spec:
  group: autoscaling.k8s.io
  names:
    kind: VerticalPodAutoscalerCheckpoint
    listKind: VerticalPodAutoscalerCheckpointList
    plural: verticalpodautoscalercheckpoints
    shortNames:
    - vpacheckpoint
    singular: verticalpodautoscalercheckpoint
  scope: Namespaced
  versions:
  - name: v1
    schema:
      openAPIV3Schema:
        description: VerticalPodAutoscalerCheckpoint is the checkpoint of the internal
          state of VPA that is used for recovery after recommender's restart.
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
          ...
```

**Step 2** Install VPA Role-Based Access Control (RBAC)
RBAC ensures that VPA has the appropriate permissions to operate within your Kubernetes cluster. To install the RBAC settings, run:

```bash
kubectl apply -f /root/vpa-rbac.yml

clusterrole.rbac.authorization.k8s.io/system:metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:vpa-actor created
clusterrole.rbac.authorization.k8s.io/system:vpa-status-actor created
clusterrole.rbac.authorization.k8s.io/system:vpa-checkpoint-actor created
clusterrole.rbac.authorization.k8s.io/system:evictioner created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-reader created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-actor created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-status-actor created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-checkpoint-actor created
clusterrole.rbac.authorization.k8s.io/system:vpa-target-reader created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-target-reader-binding created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-evictioner-binding created
serviceaccount/vpa-admission-controller created
serviceaccount/vpa-recommender created
serviceaccount/vpa-updater created
clusterrole.rbac.authorization.k8s.io/system:vpa-admission-controller created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-admission-controller created
clusterrole.rbac.authorization.k8s.io/system:vpa-status-reader created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-status-reader-binding created
```

By running these commands, the VPA will be successfully deployed to your cluster, ready to manage and adjust your pod resources dynamically.


### 3

Clone the VPA Repository and Set Up the Vertical Pod Autoscaler
You are required to clone the Kubernetes Autoscaler repository into the ``` /root ``` directory and set up the Vertical Pod Autoscaler (VPA) by running the provided script.

Steps:
Clone the repository:

First, navigate to the ``` /root ``` directory and clone the repository:

  ``` git clone https://github.com/kubernetes/autoscaler.git ```

Navigate to the Vertical Pod Autoscaler directory:

After cloning, move into the vertical-pod-autoscaler directory:

   ``` cd autoscaler/vertical-pod-autoscaler ```

Run the setup script:

Execute the provided script to deploy the Vertical Pod Autoscaler:

   ``` ./hack/vpa-up.sh ```


By following these steps, the Vertical Pod Autoscaler will be installed and ready to manage pod resources in your Kubernetes cluster.


### 4

Which of the following are the VPA CRDs that get installed as part of the Vertical Pod Autoscaler setup?

**Solution**
To check the installed VPA CRDs, you can use the following commands:

Command to check installed CRDs:

```bash
kubectl get crds | grep verticalpodautoscaler

verticalpodautoscalercheckpoints.autoscaling.k8s.io   2025-08-24T16:04:13Z
verticalpodautoscalers.autoscaling.k8s.io             2025-08-24T16:04:13Z
```

This will list the installed CRDs related to the Vertical Pod Autoscaler, allowing you to verify the correct ones. The expected output should include:

verticalpodautoscalercheckpoints.autoscaling.k8s.io
verticalpodautoscalers.autoscaling.k8s.io

### 5

How many VPA deployments typically run in the kube-system namespace after installation?

**3**

```bash
k get deploy -n kube-system 

NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
coredns                    2/2     2            2           49m
vpa-admission-controller   1/1     1            1           7m49s
vpa-recommender            1/1     1            1           7m49s
vpa-updater                1/1     1            1           7m49s
```

### 6

You are given a Kubernetes deployment file named ``` flask-app.yml ``` located in the ``` /root directory ```. Your task is to:

- Deploy the ``` flask-app.yml ``` file to the Kubernetes cluster
- After deployment, check the logs of the Vertical Pod Autoscaler(VPA) updater to ensure it is functioning correctly

Note: The pod may take some time to reach the running state.

```bash
k apply -f flask-app.yml 

deployment.apps/flask-app created
service/flask-app-service created
verticalpodautoscaler.autoscaling.k8s.io/flask-app created

```

```bash
k -n kube-system describe deploy vpa-updater

Name:                   vpa-updater
Namespace:              kube-system
CreationTimestamp:      Sun, 24 Aug 2025 16:18:10 +0000
Labels:                 <none>
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=vpa-updater
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:           app=vpa-updater
  Service Account:  vpa-updater
  Containers:
   updater:
    Image:      registry.k8s.io/autoscaling/vpa-updater:1.4.1
    Port:       8943/TCP
    Host Port:  0/TCP
    Limits:
      cpu:     200m
      memory:  1000Mi
    Requests:
      cpu:     50m
      memory:  500Mi
    Environment:
      NAMESPACE:    (v1:metadata.namespace)
    Mounts:        <none>
  Volumes:         <none>
  Node-Selectors:  <none>
  Tolerations:     <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   vpa-updater-5849bc58f9 (1/1 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  17m   deployment-controller  Scaled up replica set vpa-updater-5849bc58f9 to 1

```

### 7

You have recently deployed a Flask application to your Kubernetes cluster. However, the Vertical Pod Autoscaler (VPA) vpa-updater-XXXX pod indicates that there may be an issue with the newly deployed flask-app pods.

Inspect the logs of the vpa-updater-XXXX pod and observe the following message:

Check the logs of the vpa-updater-XXXX pod to identify any potential issues with the flask-app deployment.
When checking the logs, you see the following error message:

```bash
pods_eviction_restriction.go:226] **too few replicas** for **ReplicaSet** default/**flask-app-b6c9c4f78**
```

**Problem Analysis:**

- Flask application is running with only 1 replica pod.

- The Vertical Pod Autoscaler (VPA) needs to evict (remove) the existing pod to create a new one with updated resource settings.

- Kubernetes has a safety feature that prevents removing the last pod of a deployment to avoid service downtime.

- When you have only 1 replica and VPA tries to evict it, Kubernetes blocks this action with the error message: "too few replicas".

- VPA wants to optimize your pod's resources but cannot because Kubernetes is protecting your service availability.

- As a result, VPA cannot apply its resource recommendations, and application cannot benefit from automatic resource optimization.


**Approach to Resolve the Issue:**

1. Increase the replica count:

```bash
kubectl scale deployment flask-app --replicas=2
```

2. Verify the Deployment:

```bash
kubectl get deployment flask-app -o wide

AME        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                          SELECTOR
flask-app   2/2     2            2           14m   flask-app    kodekloud/flask-session-app:1   app=flask-app
```


Ensure that the DESIRED column shows the updated replica count, and the CURRENT column matches the desired number.

3. Check the Pod Status:

```bash
kubectl get pods -l app=flask-app

NAME                         READY   STATUS    RESTARTS   AGE
flask-app-67b666c5fc-79qsb   1/1     Running   0          86s
flask-app-67b666c5fc-stcdz   1/1     Running   0          41s
```

Wait until all pods show Running status.
You should see two pods (or more) in a Running state.

4. Verify VPA operation:

```bash
kubectl describe vpa flask-app

Name:         flask-app
Namespace:    default
Labels:       <none>
Annotations:  <none>
API Version:  autoscaling.k8s.io/v1
Kind:         VerticalPodAutoscaler
Metadata:
  Creation Timestamp:  2025-08-24T16:30:27Z
  Generation:          1
  Resource Version:    5345
  UID:                 a1d787fa-b582-473e-a55f-c548fdb4353e
Spec:
  Resource Policy:
    Container Policies:
      Container Name:  *
      Controlled Resources:
        cpu
        memory
      Max Allowed:
        Cpu:     1
        Memory:  500Mi
      Min Allowed:
        Cpu:     100m
        Memory:  100Mi
  Target Ref:
    API Version:  apps/v1
    Kind:         Deployment
    Name:         flask-app
  Update Policy:
    Eviction Requirements:
      Change Requirement:  TargetHigherThanRequests
      Resources:
        cpu
        memory
    Update Mode:  Recreate
Status:
  Conditions:
    Last Transition Time:  2025-08-24T16:31:14Z
    Status:                True
    Type:                  RecommendationProvided
  Recommendation:
    Container Recommendations:
      Container Name:  flask-app
      Lower Bound:
        Cpu:     100m
        Memory:  262144k
      Target:
        Cpu:     100m
        Memory:  262144k
      Uncapped Target:
        Cpu:     25m
        Memory:  262144k
      Upper Bound:
        Cpu:     100m
        Memory:  262144k
Events:
  Type    Reason      Age   From         Message
  ----    ------      ----  ----         -------
  Normal  EvictedPod  91s   vpa-updater  VPA Updater evicted Pod flask-app-67b666c5fc-lhbgg to apply resource recommendation.
```

This will show the current state of the VPA and any recommendations it has made. If it's working properly, you should see resource recommendations (for CPU and memory) in the output.

With 2 replicas, Kubernetes can safely remove one pod while keeping your application running, allowing VPA to work properly.



